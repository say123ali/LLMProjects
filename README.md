# LLMProjects

ğ‘ğğ­ğ«ğ¢ğğ¯ğšğ¥-ğ€ğ®ğ ğ¦ğğ§ğ­ğğ ğ†ğğ§ğğ«ğšğ­ğ¢ğ¨ğ§ (ğ‘ğ€ğ†) ğ”ğ¬ğ¢ğ§ğ  ğ‹ğšğ§ğ ğ‚ğ¡ğšğ¢ğ§
ğ‚ğ¡ğ®ğ§ğ¤ğ¢ğ§ğ  ğğ¨ğœğ®ğ¦ğğ§ğ­ğ¬ ğšğ§ğ ğ„ğ¦ğ›ğğğğ¢ğ§ğ 


âœ³ ğ’ğ©ğ¥ğ¢ğ­ğ­ğ¢ğ§ğ  ğğ¨ğœğ®ğ¦ğğ§ğ­ğ¬: 
4 methods are detailed to chunk a text:

*   CharacterTextSplitter
*   RecursiveCharacterTextSplitter
*   TokenTextSplitter
*   HTMLHeaderTextSplitter

The last one is a context aware splitter, to chunk HTML, to extract data from a website by respecting the architecture of the html. We'll have better results when applying contextual retrieving.

âœ³ ğ„ğ¦ğ›ğğğğ¢ğ§ğ  ğšğ§ğ ğ•ğğœğ­ğ¨ğ«ğğ¬ğ­ğ¨ğ«ğğ¬:
Then I used the Embedding model with LangChain and exposed another way to do it with openai directly. LangChain is using the same model under the hood â€˜ğ˜µğ˜¦ğ˜¹ğ˜µ-ğ˜¦ğ˜®ğ˜£ğ˜¦ğ˜¥ğ˜¥ğ˜ªğ˜¯ğ˜¨-ğ˜¢ğ˜¥ğ˜¢-002'.

Simple article, explaining how to use it with openai: https://lnkd.in/gF6p38Ww

Then used chroma to store embedding vectors (Explained in the short course from LangChain and deeplearning.ai), and apply Similarity search to get the most related chunks to a given question.


âœ³ğ’ğ¢ğ¦ğ¢ğ¥ğšğ«ğ¢ğ­ğ² ğ¬ğğšğ«ğœğ¡
2 methods to apply and get the score of the relatedness:
â–ª similarity_search_with_relevance_scores
â–ª similarity_search_with_score
